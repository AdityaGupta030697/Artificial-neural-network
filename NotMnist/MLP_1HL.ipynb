{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_1HL.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "iIm_q3Suwksf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bfba2bfd-fd61-4cf8-b8ab-9e1a93f0f503"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uIGWp8KXwzr9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import data from google drive\n",
        "!pip install -U -q PyDrive\n",
        " \n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        " \n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdp3nrzExOX9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad5318cf-dc56-4ce7-fe09-0dc782dc7fec"
      },
      "cell_type": "code",
      "source": [
        "file_list = drive.ListFile({'q': \"'1RxNKaI-lPF6L0jIx4hDimtsh1jNN3a3u' in parents and trashed=false\"}).GetList()\n",
        "for file1 in file_list:\n",
        "  print('title: %s, id: %s' % (file1['title'], file1['id']))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: notMNIST.pickle, id: 1rymPKySp1y2D8QS-7-8WqG57k98wk0_Q\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JeOi8dd2xUWl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download req. pickle file\n",
        "downloaded = drive.CreateFile({'id': '1rymPKySp1y2D8QS-7-8WqG57k98wk0_Q'})\n",
        "downloaded.GetContentFile('notMNIST.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Cvqm_7DxgH-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fZFYhe1_xXQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "e8b6762c-c205-48b8-d925-d970fa4137db"
      },
      "cell_type": "code",
      "source": [
        "with open('notMNIST.pickle', 'rb') as f:\n",
        "  save = pickle.load(f)\n",
        "  train_dataset = save['train_dataset']\n",
        "  train_labels = save['train_labels']\n",
        "  valid_dataset = save['valid_dataset']\n",
        "  valid_labels = save['valid_labels']\n",
        "  test_dataset = save['test_dataset']\n",
        "  test_labels = save['test_labels']\n",
        "  del save  # hint to help gc free up memory\n",
        "  print('Training set', train_dataset.shape, train_labels.shape)\n",
        "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
        "  print('Test set', test_dataset.shape, test_labels.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set (200000, 28, 28) (200000,)\n",
            "Validation set (10000, 28, 28) (10000,)\n",
            "Test set (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LsUhQ4fByAPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "68f152e6-8319-4a7e-8d8b-fe77e7348555"
      },
      "cell_type": "code",
      "source": [
        "image_size = 28\n",
        "num_labels = 10\n",
        "\n",
        "def reformat(dataset, labels):\n",
        "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
        "  # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
        "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
        "  return dataset, labels\n",
        "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
        "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
        "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
        "print('Training set', train_dataset.shape, train_labels.shape)\n",
        "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
        "print('Test set', test_dataset.shape, test_labels.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set (200000, 784) (200000, 10)\n",
            "Validation set (10000, 784) (10000, 10)\n",
            "Test set (10000, 784) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hgCxsa8vxjE-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "keEX9kJayWps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "05692f5b-53c0-4a6e-b3a7-4d0548968fed"
      },
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first layer\n",
        "model.add(Dense(1024, activation = 'relu', input_shape = (784, )))\n",
        "\n",
        "# Add the output layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Create SGD optimizer with specified learning rate: my_optimizer\n",
        "my_optimizer = SGD()\n",
        "  \n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer = my_optimizer, metrics = ['accuracy'], loss='categorical_crossentropy')\n",
        "\n",
        "# Fit the model\n",
        "with tf.device('/gpu:0'):\n",
        "  model.fit(train_dataset, train_labels, epochs=10, batch_size=64, validation_data=(valid_dataset, valid_labels))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "200000/200000 [==============================] - 17s 84us/step - loss: 0.6616 - acc: 0.8189 - val_loss: 0.5415 - val_acc: 0.8454\n",
            "Epoch 2/10\n",
            "118528/200000 [================>.............] - ETA: 6s - loss: 0.5397 - acc: 0.8472"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 17s 84us/step - loss: 0.5310 - acc: 0.8492 - val_loss: 0.5004 - val_acc: 0.8557\n",
            "Epoch 3/10\n",
            "200000/200000 [==============================] - 17s 85us/step - loss: 0.4949 - acc: 0.8582 - val_loss: 0.4751 - val_acc: 0.8621\n",
            "Epoch 4/10\n",
            " 28672/200000 [===>..........................] - ETA: 14s - loss: 0.4762 - acc: 0.8646"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 17s 84us/step - loss: 0.4686 - acc: 0.8652 - val_loss: 0.4552 - val_acc: 0.8660\n",
            "Epoch 5/10\n",
            "200000/200000 [==============================] - 17s 84us/step - loss: 0.4469 - acc: 0.8718 - val_loss: 0.4381 - val_acc: 0.8716\n",
            "Epoch 6/10\n",
            "  7488/200000 [>.............................] - ETA: 16s - loss: 0.4456 - acc: 0.8711"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 17s 84us/step - loss: 0.4285 - acc: 0.8770 - val_loss: 0.4251 - val_acc: 0.8769\n",
            "Epoch 7/10\n",
            "200000/200000 [==============================] - 17s 84us/step - loss: 0.4125 - acc: 0.8812 - val_loss: 0.4146 - val_acc: 0.8798\n",
            "Epoch 8/10\n",
            "  3840/200000 [..............................] - ETA: 16s - loss: 0.4203 - acc: 0.8742"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 17s 84us/step - loss: 0.3986 - acc: 0.8854 - val_loss: 0.4042 - val_acc: 0.8852\n",
            "Epoch 9/10\n",
            "200000/200000 [==============================] - 17s 84us/step - loss: 0.3861 - acc: 0.8894 - val_loss: 0.3973 - val_acc: 0.8842\n",
            "Epoch 10/10\n",
            "  3328/200000 [..............................] - ETA: 16s - loss: 0.3854 - acc: 0.8837"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 17s 84us/step - loss: 0.3748 - acc: 0.8925 - val_loss: 0.3894 - val_acc: 0.8867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XOMX5Tkr1e9Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "63ae49f3-71d8-41ea-f0c6-3162e3645ee4"
      },
      "cell_type": "code",
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(test_dataset, test_labels, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 62us/step\n",
            "Test loss: 0.21248694378733635\n",
            "Test accuracy: 0.9399\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}